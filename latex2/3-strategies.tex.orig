
\chapter{Machine learning in multi agent systems} 
\label{chap:Machine learning in multi agent system}

Machine learning is infused with AI techniques allowing computers to learn patterns and behaviors without explicit programming. 

In this chapter, it will be presented an overview of the state of the art in the areas related to this work. It is divided into areas:

\begin{enumerate}
	\item Types of machine learning
		\subitem Supervised Learning
		\subitem Semi-Supervised Learning
		\subitem Unsupervised Learning
		\subitem Reinforcement Learning
	\item Ensemble learning
		\subitem Stacking
		\subitem Boosting
		\subitem Bagging
\end{enumerate}

The following sections describe the work which was done in detail. Next subsections describe architecture of prepared multi-agent system. 

\newpage
\section{Types of machine learning}
Nowadays, the subject of data science has evolved that four types of machine learning approaches has been distinguished. Main difference based on the type of data they input and output, and the type of task or problem that they are intended to solve. Thus, machine learning algorithms are organized into taxonomy, based on desired outcome of the algorithm. 
Defined approaches organized in the following groups  \cite{TypesOfMachineLearning}:
\begin{outline}[]
	\1 Supervised learning --- where the algorithm maps incoming data (input) to desired output.
	\1 Unsupervised learning --- this approach models a set of inputs (unavailability of labeled examples).
	\1 Semi-supervised learning --- labeled and unlabeled examples ad combined in order of creation an appropriate function or classifier.
	\1 Reinforcement learning --- where algorithm is trained using a system of reward and punishment. Every action has impact in the environment that generates a feedback that guides the learning method.
\end{outline}

The variety of tasks that are solved by artificial intelligence forces a broader view of the issue under consideration. The essence of this is the proper selection of existing methods of artificial intelligence in order for the model created to be the best.  


\begin{center}
	\includegraphics[width=1\textwidth, keepaspectratio]{diagrams/machine_learning_model.png}
	\center
	\captionof{figure}{Various types of machine learning with examples of use in the scientific world \cite{MachineLearningModels}.} 
	\label{fig:MachineLearningTypes}
\end{center}


On Figure ~\ref{fig:MachineLearningTypes} are shown examples of different approaches of using artificial intelligence. As can be seen, machine learning algorithms have found wide application in scientific world. At the time where data and information are collected by organizations and companies in order to improve the functioning of this institution, there is the possibility of using advanced techniques that use artificial intelligence. Advanced artificial intelligence techniques have become commonplace not only due to complex multi-layer neural networks that use machine learning algorithms. Finally, for example to solving optimization problems, strategies based on meta-heuristic algorithms combined with machine learning methods are getting more popular.

\subsubsection{Learning by the agent}

As Russel and Norvig \cite{SLStructure} have designed structure of learning agent architecture to four elements:
\begin{enumerate}
	\item learning element,
	\item performance element,
	\item critic element,
	\item problem generator
\end{enumerate}

\begin{center}
	\includegraphics[width=8cm, keepaspectratio]{diagrams/related_work/SLAgents}
	\center
	\captionof{figure}{A general model of learning agents \cite{SLStructure}.} 
	\label{fig:RelatedWorkAgentLearning}
\end{center}

On the figure ~\ref{fig:RelatedWorkAgentLearning} are shown these elements and main interaction patters. Agent perceives on every moment and makes a decision depends on performance input \cite{SLKhaled}. On the one hand the agent uses feedback to determine what should be improved to increase the performance. On the other hand, the problem generator introduce agent to new informative experiences through suggesting actions.


\subsubsection{Supervised learning}
Supervised learning is a learning model built to make prediction with a given an unforeseen input instance. Known input data set and its mapped output values are taken to learn (training process) the regression or classification model. Therefore, classification and regression algorithms are used to develop predictive model which describes a given issue. Thus, the model is predictive because it relies on statistical and probabilistic techniques to predict the correct mapping values based on historical observations \cite{SupervisedUnsupervised1, SupervisedLearning}.

\begin{figure}[H]%
	\centering
	\subfloat[Linear regression]{{\includegraphics[width=5cm]{diagrams/supervised_regression_patients} }}%
	\qquad
	\subfloat[Object classification]{{\includegraphics[width=5cm]{diagrams/supervised_classification_patients} }}%
	\caption{Regression and classification as a supervised technique. Epidemic spread by distinguishing between smaller sub-tasks \cite{ClassificationAndRegression}.}%
	\label{fig:SupervisedLearningFigure}%
\end{figure}

Mostly depends on problem category which needs to be solved supervised learning provides various techniques of creating predictive model \cite{RegressionInML, ClassificationSupervisedLearning}:
\begin{enumerate}
	\item Regression techniques --- predict or forecast continuous responses. The goal is to estimate the correct output, given a feature vector. There are several types of regression concepts: simple linear regression (presented on figure  \ref{fig:SupervisedLearningFigure}), polynomial regression, support vector regression, decision tree regression, random forest regression
	\item Classification techniques (example is presented on figure  \ref{fig:SupervisedLearningFigure})--- the goal is to predict the categorical class labels (discrete, unordered values, group membership etc.) of new instances based on past observations. There are two main types of classification problem: binary classification and multi-class classification.
\end{enumerate}



In \cite{SLKhaled}, Khaled and other authors noticed that applying various supervised machine learning algorithms to the problem is not easy because there is a possibility to provide "correct" behavior for a given decision situation. In this paper, there is a consideration above multi-agent learning aspects. Furthermore, based on Weiss \cite{Weiss} publication they described aspects for characterizing learning in multi agent system:
\begin{enumerate}
	\item degree of decentralization --- learning centralized or decentralized,
	\item interaction-specific aspects (by Weiss \cite{Weiss} "level of interaction") --- nature of interactions,
	\item involvement specific aspects --- global or local learning,
	\item goal-specific aspects --- selfish or collective agent goals
\end{enumerate} 

As a consequence, they created comparison of supervised learners an the learning aspects based on other related works. Fish bank game is solved by Sniezynski \cite{Sniezynski2009SupervisedRL} using supervised rule learning. Enhance coordination in environment of heterogeneous agents are done using learning coordinated procedures by Garland and Alterman \cite{Garland2004AutonomousAT}. Learn individual's ontoligies in the field of semantic webs using inductive learning algorithms was under consideration by Williams \cite{Williams2004LearningTS}. Gehrke and Wojtusiak contemplated at route planning using rule induction algorithm \cite{Wojtusiak}. Decision tree learning was used to support plan applicability testing, through adding learning capabilities into BDI model by Airiau et. al \cite{Airaiu}. 
Hence the conclusion about supervised learners and learning aspects are formulated in presented table.

\begin{table}[H]
	\centering
	\includegraphics[width=7cm, keepaspectratio]{diagrams/related_work/Supervised_learners_vs_learning_aspects}
	\center
	\captionof{figure}{Supervised learners vs learning aspects \cite{SLKhaled}.} 
	\label{tab:LearningAspects}
\end{table}


In \cite{SLSardinha2004EngineeringML}, Sardinha, Choren, Milidiu and Pereira de Lucena proposed a methodology for introducing machine intelligence in multi-agent system. As a case study is presented Trading Agent Competition. They implemented methodology which reduces the complexity of modeling, implementing and evaluating learning techniques in large scale multi agent-system. This approach provides an improvement of perfmormance about 98\% due to the introdution of supervised machine learning algorithms. 




\subsubsection{Semi-supervised learning}

Semi-supervised learning is used to perform certain learning tasks using labeled and unlabeled data  \cite{SemiSupervisedLearning1}. In fact, it permits harnessing the large amounts of unlabeled data which exists in many use cases in combination with typically smaller sets of labeled data - hence this learning approach is useful when the cost associated with labeling is too high to allow a fully labeled training process. Therefore it can be used with methods such a classification, regression and prediction. 

\begin{center}
	\includegraphics[width=8cm, keepaspectratio]{diagrams/semi_supervised}
	\center
	\captionof{figure}{Training process performance  depends on size of labeled data on the example of blockchain data set \cite{SemiSupervisedLearning2}.} 
	\label{fig:SemiSupervisedLearning}
\end{center}

In \cite{SSPredicition} paper authors have done research on analyzation and predicition human flow. They constructed a multi-agent system which simulate and generate prepared data of people flows around a large facility. Different approach to learning (deep learning) were benchmarked. Simulation data and real data were used in the learning phase, so learning can be considered as semi-supervised learning. 

\subsubsection{Unsupervised learning}

Unsupervised learning is completely different approach than it was described in previous subsections. Most or all of the data cannot be presorted or preclassified beforehand, so the complexity of machine learning algorithm is growing dramatically causing the process more and more time intensive. 
However, this makes unsupervised learning seductive in applications where data is cheap to obtain, but labels are either expensive or not available. The main assumption of the approach is to discover the structure through common elements in data.
Popular techniques include clustering and dimensionality reduction
\cite{UnsupervisedLearning1, UnsupervisedLearning2}.

\begin{figure}[H]%
	\centering
	\subfloat[Supervised learning \cite{PolynomialRegression}]{{\includegraphics[width=5cm]{diagrams/supervised_diagram} }}%
	\qquad
	\subfloat[Unsupervised learning \cite{SupervisedUnsupervised1}]{{\includegraphics[width=5cm]{diagrams/unsupervised_diagram}}}%
	\caption{Differences in approach to learning on the example of classification objects.}%
	\label{fig:DifferencesLearning}%
\end{figure}

In \cite{Duarte2015MPDraughtsUL}, authors proposed usage of unsupervised learning injected into multi-agent system for Checkers game whose architecture is based on adaptive and multi-layer perception neural network. Besides there are several types of agents so the agents are trained for a distinct stages of the game. Each agent corresponds to a multi-layer perception neural network whose weights are updated by Temporal Difference methods \cite{TemporalDifferenceLearning}.

\begin{center}
	\includegraphics[width=8cm, keepaspectratio]{diagrams/related_work/ULCheckers}
	\center
	\captionof{figure}{Learning process for each agent \cite{Duarte2015MPDraughtsUL}.}
	\label{fig:ULChekersLearningProces}
\end{center}

In fact, at the late game each agent is an expert in a particular profile (have been trained to become an expert) of endgame board-state. On the figure\ref{fig:ULChekersLearningProces} is presented learning process for each agent.
As a conclusion: creating environment where agents have a chance to become an expert could have positive influence on working entire system and using an adaptive neural network improve overall performance of the multi-agent system.

\subsubsection{Reinforcement learning}
This learning approach has three primary components: the agent (the learner or actor), the environment (everything the agent interacts with) and actions (how agent interact). Reinforcement learning is concerned about an agent that interacts with the environment and learns an optimal policy by trail and error \cite{ReinforcementLearning2}.  Feedback loop based on which the agent is rewarded is shown on figure \ref{fig:ReinforcementLearning}. The reward received is defined by the \emph{reward function}, which maps state/action pairs to the real number \cite{ReinforcementLearning1}. The objective is for the agent to choose actions that maximize the expected reward over a given amount of time.

\begin{center}
	\includegraphics[width=9cm, keepaspectratio]{diagrams/reinforcement_learning}
	\center
	\captionof{figure}{Basic idea and elements involved in a reinforcement learning model \cite{ReinforcementLearning2}.} 
	\label{fig:ReinforcementLearning}
\end{center}
In \cite{RLRealtedWorkShops}, Deepak and Kulkarni proposed a novel approach to multi-agent cooperation for dynamic product availability in the market. Agents cooperate with each other to improve possible profits, thus it is said that retailers learn cooperatively depends on the actual situation. The problem turns out to be Markov decision process model because of the dealer's inventory strategy, refill period and entry procedure of the customers. 

Cooperation methods of cooperative reinforcement
learning of each agent have been proposed:
\begin{enumerate}
	\item group method --- rewards are distributed in a sequence of steps,
	\item dynamic method --- for each action rewards are distributed, 
	\item goal-oriented method --- when the agent achieve the goal-state then follows reward distribution. 
\end{enumerate}

\begin{center}
	\includegraphics[width=10cm, keepaspectratio]{diagrams/related_work/RLprofit}
	\center
	\captionof{figure}{Quarterly profit earned by all sellers using four methods of learning \cite{RLRealtedWorkShops}.} 
	\label{fig:RLRelatedWork}
\end{center}

As a conclusion from the article, is that cooperation methods gives a healthy performance in high-density, incompletely and composite situation, thus methods are able to guarantee best rewards through learning process and change with a group in incomplete action strategies.
\subsection{Different approach of learning in multi-agent system}
\subsubsection{Which learning approach is better?}

fajne zdanie
trying to leverage cutting edge machine learning techniques to obtain the best intelligence possible from blockchain datasets



tutaj opis supervised and unsupervised:
https://lawtomated.com/supervised-vs-unsupervised-learning-which-is-better/

comparison:
https://pl.pinterest.com/pin/434597432787064636/

dobre:
http://cdn.intechweb.org/pdfs/10694.pdf
\newpage
\section{Ensemble learning}
Ensemble learning is a machine learning paradigm where multiple learners are trained to create base model \cite{Zhou2009}. Ensemble techniques try to construct a set of hypotheses and combine them to use, however in contrast to classic machine learning approach where single instance learner learn one hypothesis from training data. Applying ensemble methods can boost weak learners to strong learners. Weak learners are better than random guess but can not make accurate predictions. In fact, there is a still possibility that, weaker learners will strengthen  better learners in decision-making process.

Considering how to create base learners, ensemble methods can be divided into two groups:
\begin{enumerate} 
	\item sequential ensemble methods - base learners are generated sequentially
	\item parallel ensemble methods - base learners are generated in parallel.
\end{enumerate}
There are common types of ensembles:
\begin{itemize}
	\item Bayes optimal classifier
	\item Bootstrap aggregating (bagging)
	\item Boosting
	\item Bayesian model averaging
	\item Bayesian model combination
	\item Bucket of models
	\item Stacking
\end{itemize}

In ensemble techniques, there are many taxonomies. Under consideration is a group of methods based on data resampling. Consequently, one method from this group generates different training sets to obtain unique learner.

\begin{center}
	\includegraphics[width=10cm, keepaspectratio]{diagrams/tradeoff}
	\center
	\captionof{figure}{Bias-variance trade-off \cite{EnsembleMethodsTradeOff}.}
	\label{fig:EnsembleTradeOff}
\end{center}
Figure \ref{fig:EnsembleTradeOff}, can shown trade-off between bias, variance, test error values and model complexity. In fact, the requirement to solve the problem using created model is to have enough degrees of freedom to resolve the underlying complexity of the data, also having not too much degrees of freedom to avoid high level of variance and be more robust.
Described techniques were mainly used as a meta-algorithms which combine several machine learning algorithms in order to decrease variance (bagging), decrease bias (boosting) and improve predictions (stacking).

\subsubsection{Stacking}
<<<<<<< HEAD
\begin{center}
	\includegraphics[width=12cm, keepaspectratio]{diagrams/stacking.jpg}
	\center
	\captionof{figure}{Dataflow using stacking as an ensemble technique \cite{stackingEnsemble}.}
	\label{fig:Stacking}
\end{center}
asdasdad
=======
Stacking as a ensemble learning method is popular to achieve greater predictive accuracy using combination of lower level base learner (In fact it is one single high-level base learner created as a combination low-level learners) \cite{StackingDefinition}. Collecting the output of each base learner into a new set of data is a first step in this approach. Care is taken to ensure that the base learners are formed from a batch of training data. A new data is treated as data for another learning problem. Then, learning algorithm is injected to solve the problem. 
\begin{center}
	\includegraphics[width=12cm, keepaspectratio]{diagrams/stacking.jpg}
	\center
	\captionof{figure}{Meta learner as a combination of base learners  \cite{stackingEnsemble}.}
	\label{fig:Stacking}
\end{center}
In the fig.\ref{fig:Stacking}
>>>>>>> develop
\subsubsection{Bootstrap Aggregating (Bagging)}
Bagging is an ensemble method for improving unstable estimation or classification schemes. Considered method is about splitting training data into smaller constant parts. For a given training set of size \textit{s}, bagging draws \textit{t} random instances with replacement (i.e. using a uniform distribution) \cite{SupervisedMachineLearningReviewClassification, BaggingDef}. Building ensembles using bagging method based on different part of training data is done with learning by single method. 

Breiman\cite{BreimanBagging} defined bagging as a variance reduction technique for a given base procedure, mostly a decision trees or functions which fitting a linear model.
Breiman also considered about number of Bootstrap replicates. In \cite{BreimanBagging}, several number of replicates where benchmarked for classification and regression, however number of enough replicates depends mainly on the data set(size and number of labels).
\begin{center}	
	\includegraphics[width=12cm, keepaspectratio]{diagrams/bagging.png}
	\center
	\captionof{figure}{In bagging, training instances can be sampled several times for the same predictor \cite{baggingEnsemble}}
	\label{fig:Bagging}
\end{center}

Figure \ref{fig:Bagging} gives a sample how Bootstrap Aggregating works on a imaginary set of data. Breiman (1996) showed the effectiveness of using these ensemble method. Bagging is effective on "unstable" learning algorithms where making small changes have large influence on predictions. In fact, Breiman in 1996 claimed about unstable learning algorithms and nowadays neural networks and decision trees are simple examples of unstable learning algorithms. 

<<<<<<< HEAD
\begin{table}[h]
=======
\begin{table}[H]
>>>>>>> develop
	\centering
	\captionof{table}{Bagged Misclassification rates. Results appeared for the 10, 25, 50, 100 numbers of bootstrap replicas used on waveform dataset \cite{BreimanBagging}.}
	\label{tab:BaggingReplicatesTable} 
	
	\begin{tabular}{|P{5cm}|P{5cm}|} \hline
		No. Bootstrap Replicates & Misclassification Rate \\ \hline
		10                       & 21.8                   \\ \hline
		25                       & 19.4                   \\ \hline
		50                       & 19.3                   \\ \hline
		100                      & 19.3                  \\ \hline
	\end{tabular}
\end{table}
In table \ref{tab:BaggingReplicatesTable} are shown the results of using bootstrap replicates and its misclassification rates. Breiman observed, that getting most of the improvement is using only 10 bootstrap replicates. The unbagged rate is 29.1. Consequently, it can be seen that the trade off between the efficiency and complexity of the learning algorithm and the profit in the form of a misclassification metric is when increasing the number of replicas we do not achieve much improvement. It is better to use less than 25 replicas on the used data set.

\subsubsection{Boosting}
Boosting keeps track of the performance of the learning algorithm and concentrates on instances that have not been correctly learned. This ensemble method also uses different subset of training data. Rather than random choosing the training instances using uniform distribution, this approach chooses the training subsets to favor the instances that have not been accurately learned \cite{SupervisedMachineLearningReviewClassification}. This approach considers homogenous weak learners and learns them sequentially in a very adaptative way to combines them following a deterministic strategy. In fact, after several steps, the predicition is done by taking a weighted vote of predictions of each classifier, with the weights which are proportional to each classifier's accuracy metric on its training set. 

\begin{center}
	\includegraphics[width=12cm, keepaspectratio]{diagrams/boosting.jpg}
	\center
	\captionof{figure}{Data flow of gradient boosting machine \cite{boostingFigureReference}.}
	\label{fig:Boosting}
\end{center}

Boosting as a ensemble method focus at reducing bias, so the base models are often considered for boosting models with low variance and high level of bias. For comparison to bagging, this approach can not be done in parallel. However, it requires careful tuning of different hyper-parameters.
Boosting involved into powerful forms i.e.: Arcing\cite{ArcingBoosting}, AdaBoosting\cite{AdaBoostBoosting}, Gradient Boosting \cite{GradientBoosting}, XGBoost \cite{XGBoosting}.
<<<<<<< HEAD
=======

\section{Application of ensemble learning methods}

>>>>>>> develop
\section{Classifiers}
\subsubsection{Decision Tree}
\subsubsection{Support Vector Regressor (SVR)}
\subsubsection{K nearest neighbours}
\subsubsection{Bayesian ridge}


Opisanie o czym jest rozdział

\section{Environment}
\subsubsection{Communication}
\subsubsection{Interactions}
sda

\section{Multi agent system}
\subsubsection{Relations}
\subsubsection{Influence}
\subsubsection{Coordinations}
asd
\subsubsection{DataManager Agent}
\subsubsection{Classifier Agent}

\subsubsection{Master Agent}

%dodac autorów do kazdej publikacji naukowej
%Zastanowić się jak uzyc boosting
%schemat komunikacyjny jako ogolny diagram
%diagram sekwencji (komunikacja głównym agentem a innymi agentami)
%rozna raprezentacja danych (sprawdzic który algorytm lepiej sobie radzi z roznymi typami danych)
%rozdzial toeretyczny wyslac (state of the art)
% uporządkować literaturę zeby była ładnie zrobiona
% przerysować tabele niewyrazne i obrazki jesli sie da
%web risk agent
%https://dl.acm.org/doi/10.1016/j.eswa.2012.01.001
